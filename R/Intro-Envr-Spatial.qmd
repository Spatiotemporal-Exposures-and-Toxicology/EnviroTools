---
title: "Spatial Analysis with Environmental Data in R"
author: Mitchell Manware, Kyle P Messier
format: html
editor: visual
---

### Internal Notes

-   **Bold text** indicates text that requires revision

-   Code chunks preceded and followed by `##########` indicate chunks that are run to render the .html document but are not included in the .html, and may require edits before final rendering.

# Unit 1: Access, Import, and Primary Analyses

Environmental research relies on various types of spatial, temporal, and spatio-temporal data to accurately measure, predict, and model exposures.

This vignette will introduce packages equipped to handle the various types of data often used in environmental research. The vignette will also show/teach how to perform various analyses for each unique type of spatial data. Analyses include:

-   Downloading data from a URL

-   Importing data with various packages

-   Checking data type, structure, and class

-   Reclassifying data

-   Computing summary and zonal statistics

-   Plotting individual and multiple data sets

Requires revision: This vignette assumes users' understanding of R **coding principles**, such as basic functions `+ - * / =`, "variables", and `$indexing`. For a primer on R, see <https://cran.r-project.org/doc/manuals/R-intro.pdf>. The terminology/jargon used throughout the vignette assumes users' understanding of primary spatial data concepts, such as the definitions of point, polygon, and raster data types. For more information on data types, see [1. Simple Features for R](https://r-spatial.github.io/sf/articles/sf1.html#what-is-a-feature) for a primer on point and polygon data types, and see [Introduction to Raster Data](https://datacarpentry.org/organization-geospatial/01-intro-raster-data) for a primer on raster data.

::: callout-important
The exploratory analyses performed in this vignette are designed for educational purposes only. The results of the following analyses are not peer-reviewed findings, nor do they attempt to answer any hypotheses.

Additionally, the **views/opinions** conveyed in this vignette reflect the **views/opinions** of the authors alone, and do not reflect the **views/opinions** of the National Institutes of Health (NIH) or the National Institute of Environmental Health Sciences (NIEHS).
:::

## 0. Introduction

### 0.1 Data Sources

The exploratory analyses performed in this vignette utilize free and publicly available spatial data. The code is designed to access each specific file used for the exploratory analyses, but a description of each data source and data set is available below.

| Data                                | Data Type | Producer                                               | Link                                                                                        |
|----------------|----------------|----------------|--------------------------|
| PM~2.5~ Daily Observations          | Point     | Environmental Protection Agency (EPA)                  | <https://aqs.epa.gov/aqsweb/airdata/download_files.html>                                    |
| Wildfire Smoke Plumes               | Polygon   | National Oceanic and Atmospheric Administration (NOAA) | <https://www.ospo.noaa.gov/Products/land/hms.html>                                          |
| United States Cartographic Boundary | Polygon   | United States Census Bureau                            | <https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html> |
| Land Surface Temperature            | Raster    | National Oceanic and Atmospheric Administration (NOAA) | <https://psl.noaa.gov/data/gridded/data.narr.html>                                          |

: Exploratory analyses data sources

### 0.2 Download and Load Packages

Many different R packages can be used to create, import, analyze, and export spatial data. If you have not used these packages previously, they may not be installed on your machine. The following chunk of code installs and imports the required packages that are not currently **on** your machine, so run the code before proceeding with the exploratory analyses.

::: callout-note
Installing and importing new packages may required R to restart.
:::

```{r, warning=FALSE, message=FALSE, results=FALSE}
vignette_packages = c("dplyr", "ggplot2", "ggpubr", "sf", "sftime",
                      "terra", "tidyterra", "utils")

for(v in 1:length(vignette_packages)){
  if (vignette_packages[v] %in% installed.packages() == FALSE){
    install.packages(vignette_packages[v])
  }
}

library(dplyr); library(ggplot2); library(ggpubr); library(sf);
library(sftime); library(terra); library(tidyterra); library(utils)
```

## 1. Point Data with `sf`

Air pollution monitoring data from the United States Environmental Protection Agency (EPA) will be used to demonstrate **using** point data with the `sf` package.

### 1.0 Access, download, and unzip

Define a variable to store the website URL where the data exists, and a second variable to store the file path (including `.zip`) **for where** the file should be saved. The `utils::download.file()` function downloads the file according to the defined URL and destination file.

::: callout-note
Multiple chunks of code in this vignette will contain `/   YOUR FILE PATH   /`. To run the code on your machine, substitute `/   YOUR FILE PATH   /` with the file path where you would like to store the vignette data (ie. `Users/example_name/Documents/vignette_data/"`).
:::

```{r, results=FALSE, warning=FALSE, message=FALSE, results='hide', eval=FALSE}
url_epa = "https://aqs.epa.gov/aqsweb/airdata/daily_88101_2021.zip"

destination_epa = "/   YOUR FILE PATH   /epa_data.zip"

download.file(url_epa,
              destination_epa)
```

```{r, include = FALSE, eval=FALSE}
################################################################################
## NEED TO CHANGE eval=TRUE for rendering
################################################################################
url_epa = "https://aqs.epa.gov/aqsweb/airdata/daily_88101_2021.zip"
destination_epa = "/Volumes/SET/Projects/EnviroTools/input/epa/epa_data.zip"
download.file(url_epa,
              destination_epa)
################################################################################
```

The file downloaded from the EPA website is a `.zip` file. Zip files need to be unzipped (decompressed) in order to access the data within. Unzip the EPA air pollution file with `utils::unzip()`.

::: callout-warning
Unzipping a `.zip` file will decompress the contents within. Spatial data sets can be very large (ie. 1GB \<), so check the size of the data before unzipping on your machine.
:::

```{r, results=FALSE, warning=FALSE, message=FALSE, results='hide', eval=FALSE}
unzip("/   YOUR FILE PATH   /epa_data.zip",
      list = TRUE)
```

```{r, echo=FALSE}
################################################################################
unzip("/Volumes/SET/Projects/EnviroTools/input/epa/epa_data.zip",
      list = TRUE)
################################################################################
```

The numeric value size of the file is listed under `Length`.

After inspecting the file size, unzip `epa_data.zip`.

```{r, warning=FALSE, message=FALSE, results=FALSE}
unzip("/   YOUR FILE PATH   /epa_data.zip")
```

```{r, echo=FALSE, eval=FALSE}
################################################################################
## NEED TO CHANGE eval=TRUE for rendering
################################################################################
unzip("/Volumes/SET/Projects/EnviroTools/input/epa/epa_data.zip",
      exdir = "/Volumes/SET/Projects/EnviroTools/input/epa")
################################################################################
```

Inspecting the file with `utils::unzip(list = TRUE)` returned the size of the file, but also the **name of the actual data file of interest** (`daily_88101_2021.csv`). The desired data file can also be identified by using `list.files()`.

::: callout-note
If `/   YOUR FILE PATH   /` is a directory with other contents (ie. `/Users/example_name/Desktop/`), other files names may be returned.
:::

```{r, warning=FALSE, message=FALSE, results=FALSE}
list.files("/   YOUR FILE PATH   /")
```

```{r, echo=FALSE}
################################################################################
list.files("/Volumes/SET/Projects/EnviroTools/input/epa")
################################################################################
```

### 1.1 Import

Now that the contents of `epa_data.zip` have been saved on your machine and `daily_88101_2021.csv` has been identified as the data set of interest, import the data with `sf::st_read()`.

```{r, eval=FALSE}
pm = st_read("/   YOUR FILE PATH   /daily_88101_2021.csv")
```

```{r, echo=FALSE, warning=TRUE, cache=FALSE, results='hide'}
################################################################################
pm = st_read("/Volumes/SET/Projects/EnviroTools/input/epa/daily_88101_2021.csv")
################################################################################
```

::: callout-note
You will notice that the previous line of code returns a `Warning:` message. **This warning lets the user know that the imported `.csv` file does not have spatial features, but it has still been imported as a normal `data.frame`**.
:::

### 1.2 Inspect structure

Inspect the structure of `pm` to see its class, column names, column classes, and the first two (specified by `vec.len = 2`) data points from each column.

```{r}
str(pm,
    vec.len = 2)
```

`pm` is a very large data set (590208 observations for 29 variables). Each of these variables conveys important information pertaining to air pollution monitoring **data**, but not all of the variables will be utilized in the exploratory analyses.

### 1.3 Subset

Reduce the number of variables in `pm` with `subset()`. The `select =` argument indicates that certain variables are being "selected", but all observations of these variables will be retained. The following variables will be retained for the exploratory analyses: state code, county code, site number, latitude, longitude, state name, date, and arithmetic mean.

Re-running `str(pm)` after running the `subset` shows that all observations (n = 590208) of the desired variables (n = 8) have been retained.

```{r}
pm = subset(pm, select = c(State.Code,
                           County.Code,
                           Site.Num,
                           Latitude,
                           Longitude,
                           State.Name,
                           Date.Local,
                           Arithmetic.Mean))
str(pm,
    vec.len = 2)
```

### 1.4 Reclassify

When the `str()` function is run, `: chr` **follows** each of the variable names, indicating that the variable is of class `character`. This can also be determined by the quotations **encasing** the first two data points of each variable (ie. `$ State.Code    : chr "01" "01" ...`).

The class of the variable depends on the information stored within that variable. For example, `character` class data is **appropriate** for words (ie. `$State.Name`), but not for numeric measurements (ie. `$Arithmetic.Mean`) or dates (ie. `$Date.Local`).

The `as.` family of functions is useful for converting data to a different class. For the purposes of these exploratory analyses, only `$Date.Local` and `$Arithmetic.Mean` will be reclassified.

```{r}
pm$Date.Local = as.Date(pm$Date.Local)
pm$Arithmetic.Mean = as.numeric(pm$Arithmetic.Mean)
```

After running the `as.` functions, ensure that the variable has been converted to the desired class.

```{r}
class(pm$Date.Local); class(pm$Arithmetic.Mean)
```

### 1.5 Convert to `sf` object

With the variables of interest selected and the **important reclassifications made**, `pm` can be converted to an `sf` object. Conversion to an `sf` object **spatially enables** the data frame in order to conduct spatial analyses.

The `sf::st_as_sf()` function creates a `$geometry` field based on the coordinates contained in the `pm` data frame. The columns containing the x and y coordinates are specified in the argument `coords = c()`.

```{r}
pm_sf = st_as_sf(pm,
                 coords = c("Longitude", "Latitude"))
```

After running the `sf::st_as_sf()` function, inspect the classes of `pm_sf` and `pm_sf$geometry` to see the changes.

```{r}
class(pm_sf); class(pm_sf$geometry)
```

You will notice that `class(pm_sf)` returned two values, `"sf"` and `"data.frame"`. This indicates that `pm_sf` contains non-spatial data and a spatially defined geometry.

![sf::st_sf_sf() visual](/Volumes/SET/Projects/EnviroTools/input/figures/st_as_sf_visual.png)

### 1.6 Coordinate reference system and projection

**It is important to know the coordinate reference system and projection of the spatial data that is being used.** For a detailed explanation of coordinate reference systems and projections, please see **LINK**.

The coordinate reference system of an `sf` object can be checked with `sf::st_crs()`.

```{r}
st_crs(pm_sf)
```

Running the function shows that `pm_sf` does have a coordinate reference system assigned. An `sf` object can be set to a coordinate reference system using the same function. For this example the World Geodesic System 1984 (WGS 84) will be used. The EPSG code of WGS 84 is `4326`.

```{r}
st_crs(pm_sf) = 4326
st_crs(pm_sf)
```

After assigning a coordinate reference system to the data, the data can be projected (transformed) to a different projected coordinate system with `sf::st_transform()`.

The area of interest for these exploratory analyses is the the coterminous United States, so the Albers Equal Area projected coordinate system will be used. The EPSG code of the Albers Equal Area projection for the coterminous United States is `5070`.

```{r}
pm_sf = st_transform(pm_sf,
                     5070)
```

### 1.7 Plot

Plotting spatial data is important for visual inspection of the data itself and for **communicating** spatial patterns in the data. The packages `ggplot2` and `ggpubr` are **useful** for creating publication quality plots with spatial data, non-spatial data, and **a combination of both**.

Plot the point locations of each air pollution monitoring station included in the `pm_sf` data set with `ggplot2::ggplot()`. Identifying the data set to be plotted within the `ggplot2::geom_sf()` argument informs the function that the data is an `sf` object.

```{r}
ggplot()+
  geom_sf(data = pm_sf)+
  ggtitle("EPA Air Pollution Monitoring Locations (2021)")+
  theme_pubr()+
  theme(plot.title = element_text(hjust = 0.5))+
  grids()
```

The plotted points show the distribution of monitoring locations throughout the Untied States, but do not convey any information about the concentrations of PM~2.5~ measurements at each location. Inspect the summary statistics of the parameter of interest before **plotting/mapping it**.

```{r}
summary(pm_sf$Arithmetic.Mean); sd(pm_sf$Arithmetic.Mean)
```

**Histograms are useful for visualizing the distribution of data.** Create a histogram by adding `ggplot2::geom_histogram()` as an argument to the `ggplot2::ggplot()` function.

```{r}
ggplot(data = pm_sf,
       aes(Arithmetic.Mean))+
  geom_histogram(fill = "slateblue",
                 binwidth = 5)+
  ggtitle("Particulate Matter Measurements at EPA Monitoring Locations (2021)")+
  xlab(expression("PM"[2.5]*" Concentration (µg/m"^3*")"))+
  ylab("Number of Measurements")+
  theme_pubr()+
  theme(plot.title = element_text(hjust = 0.5))+
  grids()
```

### 1.8 Calculate annual mean

A **summary statistic** that may be of interest to researchers is the mean measurement for each location for a specific period of time. For this example, the mean concentration for each monitoring location for all observations recorded in 2021 will be calculated. To do so, a unique identification code must be created for each monitoring location. This `$Monitor.ID` can be created by concatenating the state code, county code, and site number.

```{r}
pm_sf$Monitor.ID = paste0(pm_sf$State.Code,
                          pm_sf$County.Code,
                          pm_sf$Site.Num)
```

The number of unique monitor identification codes should be equal to the number of unique geometries.

```{r}
length(unique(pm_sf$Monitor.ID)) == length(unique(pm_sf$geometry))
```

Functions and syntax from the `dplyr` package will be used to calculate the mean PM~2.5~ concentration measured at each monitoring location.

::: callout-note
Including `State.Name` in the `group_by()` arguement will retain the state name for each monitoring location.
:::

```{r, warning=FALSE, message=FALSE}
pm_mean =
  pm_sf %>%
  group_by(Monitor.ID, State.Name) %>%
  summarise(Annual.Mean = mean(Arithmetic.Mean))
```

Inspect the summary statistics of mean PM~2.5~ concentration measurements.

```{r}
summary(pm_mean$Annual.Mean); sd(pm_mean$Annual.Mean)
```

Recreate the plot of air pollution monitoring locations, but color each point according to the annual mean concentration of PM~2.5~ at each location.

```{r}
ggplot()+
  geom_sf(data = pm_mean,
          aes(color = Annual.Mean))+
  scale_color_viridis_b(expression("PM"[2.5]*" Concentrations (µg/m"^3*")"))+
  ggtitle("Mean Particulate Matter Concentration at EPA Monitoring Locations")+
  theme_pubr(legend="bottom")+
  theme(plot.title = element_text(hjust = 0.5))+
  grids()
```

### 1.9 Exploratory analysis: highest annual means

The previous plot shows three monitoring locations in California with very high (\> 20 ug/m^3^) mean concentrations of particulate matter. Create a subset of the `pm_sf` data set with only these three monitors.

First, identify the unique monitor identification codes.

```{r}
max_monitors =
  pm_mean %>%
  arrange(Annual.Mean) %>%
  tail(n = 3)
max_monitors_id = max_monitors$Monitor.ID
```

Create a subset of `pm_sf` according to the monitor identification codes in `max_monitors_id`.

```{r}
pm_max = subset(pm_sf,
                subset = Monitor.ID == max_monitors_id)
```

Together, the `ggplot2::geom_line()` and `ggplot2::facet_wrap()` arguments can be used to compare all the measurements from each of the three highest monitoring locations in a single plot.

```{r}
ggplot(data = pm_max,
       aes(x = Date.Local,
           y = Arithmetic.Mean,
           group = Monitor.ID,
           color = Monitor.ID))+
  geom_line()+
  ggtitle("Highest Annual Mean Concentrations of PM2.5")+
  facet_wrap(~ Monitor.ID,
             nrow = 3)+
  xlab("Date")+
  ylab(expression("PM"[2.5]*" Concentrations (µg/m"^3*")"))+
  theme_pubr(legend = "bottom")+
  theme(plot.title = element_text(hjust = 0.5))
```

Alternatively, the `ggplot2::geom_boxplot()` function compares the median, interquartile range, and outliers of the three monitors' measurements.

```{r}
ggplot(data = pm_max,
       aes(x = Monitor.ID,
           y = Arithmetic.Mean,
           fill = Monitor.ID))+
  geom_boxplot()+
  xlab("Monitor ID")+
  ylab(expression("PM"[2.5]*" Concentrations (µg/m"^3*")"))+
  theme_pubr(legend = "none")
```

This concludes section 1. Point Data with `sf`. Unit 2 of this vignette series will explore more specific analyses that can be conducted with `sf` point data.

# ============= BREAK ==============

## 2. Polygon Data

### 2.0 Access and download

Define day, year, and month of interest

```{r, results=FALSE, warning=FALSE, message=FALSE, results='hide'}
day = "01"
month = "09"
year = "2023"
```

Set link to data access URL and specify saving location.

```{r, results=FALSE, warning=FALSE, message=FALSE, results='hide', eval=FALSE}
# specify the URL where data is stored based on date variables of interest
url_noaa = paste0("https://satepsanone.nesdis.noaa.gov/pub/FIRE/web/HMS/Smoke_Polygons/Shapefile/",
                  year,
                  "/",
                  month,
                  "/hms_smoke",
                  year,
                  month,
                  day,
                  ".zip")

# specify where to save downloaded data
destination_noaa = paste0("/   YOUR FILE PATH   /noaa_smoke",
                          year,
                          month,
                          day,
                          ".zip")

# download the data
download.file(url_noaa,
              destination_noaa)
```

```{r, include = FALSE, eval=FALSE}
################################################################################
## NEED TO CHANGE eval=TRUE for rendering
################################################################################
url_noaa = paste0("https://satepsanone.nesdis.noaa.gov/pub/FIRE/web/HMS/Smoke_Polygons/Shapefile/",
                  year,
                  "/",
                  month,
                  "/hms_smoke",
                  year,
                  month,
                  day,
                  ".zip")
destination_noaa = paste0("/Volumes/SET/Projects/EnviroTools/input/noaa/noaa_smoke",
                          year,
                          month,
                          day,
                          ".zip")
download.file(url_noaa,
              destination_noaa)
################################################################################
```

Unzip downloaded file.

```{r, warning=FALSE, message=FALSE, results=FALSE}
unzip("/   YOUR FILE PATH   /noaa_smoke20230901.zip")
```

```{r, include=FALSE, eval=FALSE}
################################################################################
## NEED TO CHANGE eval=TRUE for rendering
################################################################################
unzip("/Volumes/SET/Projects/EnviroTools/input/noaa/noaa_smoke20230901.zip",
      exdir = "/Volumes/SET/Projects/EnviroTools/input/noaa")
################################################################################
```

Identify file name.

```{r, warning=FALSE, message=FALSE, results=FALSE}
list.files("/   YOUR FILE PATH   /")
```

```{r, echo=FALSE}
################################################################################
list.files("/Volumes/SET/Projects/EnviroTools/input/noaa")
################################################################################
```

### 2.1 Polygon data with `sf`

#### 2.1.1 Import

```{r, eval=FALSE}
smoke = st_read("/   YOUR FILE PATH   /hms_smoke20230901.shp")
```

```{r, echo=FALSE, warning=TRUE, cache=FALSE, results='hide'}
################################################################################
smoke = st_read("/Volumes/SET/Projects/EnviroTools/input/noaa/hms_smoke20230901.shp")
################################################################################
```

#### 2.1.2 Inspect contents

```{r}
str(smoke); st_crs(smoke)
```

#### 2.1.3 Inspect parameter of interest

```{r}
unique(smoke$Density); class(smoke$Density)
```

#### 2.1.4 Reclassify parameter of interest

```{r}
smoke$Density = factor(smoke$Density,
                       levels = c("Light", "Medium", "Heavy"))
```

#### 2.1.5 Plot polygons with `ggplot2`

```{r}
ggplot()+
  geom_sf(data = smoke,
          aes(fill = Density))+
  scale_fill_manual("Smoke Density",
                    values = c("lightgreen", "lightgoldenrod", "tomato"))+
  ggtitle("Wildfire Smoke Plumes (September 1, 2023)")+
  theme_pubr(legend = "bottom")+
  theme(plot.title = element_text(hjust = 0.5))+
  grids()
```

#### 2.1.6 Combine polygons based on density classification

Create variable with density types.

```{r}
dens = unique(smoke$Density)
```

Union polygons by density type with new date column.

```{r}
smoke_density =
  smoke %>%
  group_by(Density) %>%
  summarise(geometry = st_union(geometry),
            Date = paste0(year,
                          month,
                          day))
```

Plot union-ed polygons.

```{r}
ggplot()+
  geom_sf(data = smoke_density,
          aes(fill = Density))+
  scale_fill_manual("Smoke Density",
                    values = c("lightgreen", "lightgoldenrod", "tomato"))+
  ggtitle("Wildfire Smoke Plumes (September 1, 2023)")+
  theme_pubr(legend = "bottom")+
  theme(plot.title = element_text(hjust = 0.5))+
  grids()
```

#### 2.1.6 Import United States state boundary polygon data

Set link to data access URL and specify saving location.

```{r, eval=FALSE}
# specify the URL where data is stored
url_states = "https://www2.census.gov/geo/tiger/GENZ2018/shp/cb_2018_us_state_500k.zip"

# specify where to save downloaded data
destination_states = "/   YOUR FILE PATH   /states.zip"

# download the data
download.file(url_states,
              destination_states)
```

```{r, include = FALSE, eval=FALSE}
################################################################################
## NEED TO CHANGE eval=TRUE for rendering
################################################################################
url_states = "https://www2.census.gov/geo/tiger/GENZ2018/shp/cb_2018_us_state_500k.zip"
destination_states = "/Volumes/SET/Projects/EnviroTools/input/states/states.zip"
download.file(url_states,
              destination_states)
################################################################################
```

Unzip downloaded data.

```{r, eval=FALSE}
unzip("/   YOUR FILE PATH   /states.zip")
```

```{r, include=FALSE, eval=FALSE}
################################################################################
## NEED TO CHANGE eval=TRUE for rendering
################################################################################
unzip("/Volumes/SET/Projects/EnviroTools/input/states/states.zip",
      exdir = "/Volumes/SET/Projects/EnviroTools/input/states")
################################################################################
```

Identify file name.

```{r, eval=FALSE}
list.files("/   YOUR FILE PATH   /")
```

```{r, echo=FALSE}
################################################################################
list.files("/Volumes/SET/Projects/EnviroTools/input/states")
################################################################################
```

Import data.

```{r, eval=FALSE}
states = st_read("/   YOUR FILE PATH   /cb_2018_us_state.shp")
```

```{r, include=FALSE}
################################################################################
states = st_read("/Volumes/SET/Projects/EnviroTools/input/states/cb_2018_us_state_500k.shp")
################################################################################
```

Inspect United States polygons.

```{r}
str(states); st_crs(states)
```

Subset to contiguous United States.

```{r}
# define list of state and territories to be removed
remove = c("Alaska",
            "Hawaii",
            "Puerto Rico",
            "United States Virgin Islands",
            "Commonwealth of the Northern Mariana Islands",
            "Guam",
            "American Samoa")

# remove states and territories
conus = subset(states,
               !NAME %in% remove)
```

Plot contiguous United States boundaries.

```{r}
ggplot()+
  geom_sf(data = conus)+
  ggtitle("Contiguous United States Boundaries")+
  theme_pubr()+
  theme(plot.title = element_text(hjust = 0.5))+
  grids()
```

#### 2.1.7 Plot smoke plumes and state boundaries `sf`

Set matching coordinate reference systems.

```{r, warning=FALSE}
st_crs(smoke_density) = st_crs(conus)
st_crs(smoke_density) == st_crs(conus)
```

Set matching projections (USA Contiguous Albers Equal Area Conic).

```{r}
smoke_density = st_transform(smoke_density,
                             5070)
conus = st_transform(conus,
                     5070)
```

Create plot.

```{r}
ggplot()+
  geom_sf(data=smoke_density,
          aes(fill=Density))+
  scale_fill_manual("Smoke Density",
                    values=c("lightgreen", "lightgoldenrod", "tomato"))+
  geom_sf(data=conus,
          fill="transparent")+
  ggtitle("Wildfire Smoke Plumes (September 1, 2023)")+
  theme_pubr(legend="bottom")+
  theme(plot.title = element_text(hjust = 0.5))+
  grids()
```

#### 2.1.8 Crop smoke polygons to contiguous United States bounding box

```{r, warning=FALSE}
smoke_crop = st_crop(smoke_density,
                     conus)
```

#### 2.1.9 Plot cropped smoke polygons.

```{r}
ggplot()+
  geom_sf(data=smoke_crop,
          aes(fill=Density))+
  scale_fill_manual("Smoke Density",
                    values=c("lightgreen", "lightgoldenrod", "tomato"))+
  geom_sf(data=conus,
          fill="transparent")+
  ggtitle("Wildfire Smoke Plumes (September 1, 2023)")+
  theme_pubr(legend="bottom")+
  theme(plot.title = element_text(hjust = 0.5),
        axis.line = element_blank(),
        axis.ticks = element_blank(),
        axis.text = element_blank())+
  grids()
```

# ============= BREAK ==============

### 2.2 Polygon data with `terra`

#### 2.2.0 Access and download same as with `sf`

#### 2.2.1 Import (wildfire and boundary data)

```{r, eval=FALSE}
smoke_t = vect("/   YOUR FILE PATH   /hms_smoke20230901.shp")
states_t = vect("/   YOUR FILE PATH   /cb_2018_us_state_500k.shp")
```

```{r, echo=FALSE, warning=TRUE, cache=FALSE, results='hide'}
################################################################################
smoke_t = vect("/Volumes/SET/Projects/EnviroTools/input/noaa/hms_smoke20230901.shp")
states_t = vect("/Volumes/SET/Projects/EnviroTools/input/states/cb_2018_us_state_500k.shp")
################################################################################
```

#### 2.2.2 Inspect contents

```{r}
str(smoke_t); str(states_t)
```

#### 2.2.3 Set up parameters of interest

```{r}
smoke_t$Density = factor(smoke_t$Density,
                         levels=c("Light", "Medium", "Heavy"))
conus_t = subset(states_t,
                 !states_t$NAME %in% remove)
```

#### 2.2.4 Set matching coordinate reference systems and projections

```{r}
crs(smoke_t) = crs(conus_t)
smoke_t = project(smoke_t,
                  "EPSG:5070")
conus_t = project(conus_t,
                  "EPSG:5070")
```

#### 2.2.5 Combine polygons based on density classification

```{r}
smoke_density_t = terra::aggregate(smoke_t,
                                   by="Density",
                                   dissolve=TRUE)
```

New `smoke_density_t` is SpatVector with 3 geometries.

```{r}
smoke_density_t
```

#### 2.2.6 Plot smoke plumes and state boundaries `terra`

```{r}
ggplot()+
  geom_spatvector(data=smoke_density_t,
                  aes(fill=Density))+
  scale_fill_manual("Smoke Density",
                    values=c("lightgreen", "lightgoldenrod", "tomato"))+
  geom_spatvector(data=conus_t,
                  fill="transparent")+
  ggtitle("Wildfire Smoke Plumes (September 1, 2023)")+
  theme_pubr(legend="bottom")+
  theme(plot.title = element_text(hjust = 0.5))+
  grids()
```

#### 2.2.7 Crop smoke data to state boundaries

```{r}
smoke_density_crop_t = terra::crop(smoke_density_t,
                                   conus_t)
```

```{r}
ggplot()+
  geom_spatvector(data=smoke_density_crop_t,
                  aes(fill=Density))+
  scale_fill_manual("Smoke Density",
                    values=c("lightgreen", "lightgoldenrod", "tomato"))+
  geom_spatvector(data=conus_t,
                  fill="transparent")+
  ggtitle("Wildfire Smoke Plumes in the United States (September 1, 2023)")+
  theme_pubr(legend="bottom")+
  theme(plot.title = element_text(hjust = 0.5),
        axis.line = element_blank(),
        axis.ticks = element_blank(),
        axis.text = element_blank())
```

#### 2.2.8 Identify presence of smoke plumes in each state

Identify where smoke polygons intersect state boundaries.

```{r}
conus_smoke = data.frame(t(relate(smoke_density_t,
                                  conus_t,
                                  relation="intersects")))
```

Set column names to match density type.

```{r}
colnames(conus_smoke) = c("Light", "Medium", "Heavy")
```

Combine smoke plume coverage presence with state boundaries.

```{r}
conus_t = cbind(conus_t,
                conus_smoke)
```

#### 2.2.9 Compare presence of smoke plume coverage across states

New variable with smoke density classifications as character.

```{r}
dens_c = c("Light", "Medium", "Heavy")
```

For loop creating identification plots for each density type.

```{r, warning=FALSE}
for(d in 1:length(dens_c)){
  
  # define color palette based on smoke density
  if(dens_c[d] == "Light"){
    color_values = c("lightgrey", "lightgreen")
  } else if(dens_c[d] == "Medium"){
    color_values = c("lightgrey", "lightgoldenrod")
  } else if(dens_c[d] == "Heavy"){
    color_values = c("lightgrey", "tomato")
  }
  
  print(
    ggplot()+
      geom_spatvector(data=conus_t,
                      aes_string(fill=dens_c[d]))+
      scale_fill_manual(paste0(dens_c[d],
                               " Smoke Plume Coverage Present"),
                        values=color_values)+
      theme_pubr(legend="bottom")+
      theme(plot.title = element_text(hjust = 0.5),
            axis.line = element_blank(),
            axis.ticks = element_blank(),
            axis.text = element_blank())
  )
  
}
```

# ============= BREAK ==============

## 3. Raster Data

### 3.0 Access and download

Define year of interest.

```{r, results=FALSE, warning=FALSE, message=FALSE, results='hide'}
year = "2021"
```

Set link to data access URL and specify saving location.

```{r, results=FALSE, warning=FALSE, message=FALSE, results='hide', eval=FALSE}
# specify the URL where data is stored based on year variable of interest
url_narr = paste0("https://downloads.psl.noaa.gov//Datasets/NARR/Dailies/monolevel/air.2m.",
                  year,
                  ".nc")

# specify where to save downloaded data
destination_narr = paste0("/   YOUR FILE PATH   /narr_air2m_",
                          year,
                          ".nc")

# download the data
download.file(url_narr,
              destination_narr)
```

```{r, include = FALSE, eval=FALSE}
################################################################################
## NEED TO CHANGE eval=TRUE for rendering
################################################################################
url_narr = paste0("https://downloads.psl.noaa.gov//Datasets/NARR/Dailies/monolevel/air.2m.",
                  year,
                  ".nc")
destination_narr = paste0("/Volumes/SET/Projects/EnviroTools/input/narr/narr_air2m_",
                          year,
                          ".nc")
download.file(url_narr,
              destination_narr)
################################################################################
```

Identify file name.

```{r, warning=FALSE, message=FALSE, results=FALSE}
list.files("/   YOUR FILE PATH   /")
```

```{r, echo=FALSE}
################################################################################
list.files("/Volumes/SET/Projects/EnviroTools/input/narr")
################################################################################
```

### 3.1 Import data with `terra`

```{r, eval=FALSE}
narr = rast(paste0("/   YOUR FILE PATH   /narr_air2m_",
                   year,
                   ".nc")
```

```{r, echo=FALSE, warning=TRUE, cache=FALSE, results='hide'}
narr = rast(paste0("/Volumes/SET/Projects/EnviroTools/input/narr/narr_air2m_",
                    year,
                    ".nc"))
```

### 3.2 Inspect contents

```{r}
narr
```

### 3.3 Check coordinate reference system

```{r}
crs(narr,
    describe=TRUE)
```

#### 3.3.1 Set cooridnate reference system

########################################## 

To match the coordinate reference systems of the previous data, set the coordinate reference system to USA Contiguous Albers Equal Area Conic.

```{r}
# crs(narr) = "EPSG:5070"
```

#### 3.3.2 Project the data

```{r}
narr = project(narr, "EPSG:5070")
crs(narr,
    describe=TRUE)
```

### 3.4 Visually inspect the data

Check for matching coordinate reference system with contiguous United States borders

```{r}
crs(conus_t) == crs(narr)
```

Plot only the first layer.

```{r}
ggplot()+
  geom_spatraster(data=narr$air_1)+
  scale_fill_continuous(type="viridis",
                        na.value=NA,
                        "Temperature (°K)")+
  ggtitle("Air Temperature at 2m Height (January 1, 2021)")+
  geom_spatvector(data=conus_t,
                  fill="transparent",
                  color="black")+
  theme_pubr(legend="bottom")+
  theme(plot.title = element_text(hjust = 0.5))+
  grids()
```

### 3.5 Crop temperature data

```{r}
narr_crop = crop(narr,
                 conus_t,
                 mask=TRUE)
```

### 3.6 Plot cropped temperature data

```{r}
ggplot()+
  geom_spatraster(data=narr_crop$air_1)+
  scale_fill_continuous(type="viridis",
                        na.value=NA,
                        "Temperature (°K)")+
  ggtitle("Air Temperature at 2m Height (January 1, 2021)")+
  geom_spatvector(data=conus_t,
                  fill="transparent",
                  color="black")+
  theme_pubr(legend="bottom")+
  theme(plot.title = element_text(hjust = 0.5),
        axis.line = element_blank(),
        axis.ticks = element_blank(),
        axis.text = element_blank())
```

### 3.7 Convert degrees Kelvin to degrees Celsius

Performing basic mathematical and statistical operations on raster and SpatRaster objects is simple.

```{r}
narr_crop_c = narr_crop-273.15
```

### 3.8 Calculate annual mean and range of temperature for each grid cell

```{r}
narr_crop_c$mean = mean(narr_crop_c)
narr_crop_c$range = max(narr_crop_c) - min(narr_crop_c)
summary(narr_crop_c$mean); summary(narr_crop_c$range)
```

Plot the annual mean and range of temperatures.

```{r, warning=FALSE}
ggplot()+
  geom_spatraster(data=narr_crop_c[[c("mean", "range")]])+
  scale_fill_continuous(type="viridis",
                        na.value=NA,
                        "Temperature (°C)")+
  facet_wrap(~lyr)+
  ggtitle("Air Temperature in 2021")+
  geom_spatvector(data=conus_t,
                  fill="transparent",
                  color="black")+
  theme_pubr(legend="bottom")+
  theme(plot.title = element_text(hjust = 0.5),
        axis.line = element_blank(),
        axis.ticks = element_blank(),
        axis.text = element_blank())
```

### 3.9 Calculate average annual temperature for each state

```{r, warning=FALSE}
conus_t$MEAN = zonal(narr_crop_c$mean,
                     conus_t,
                     fun = "mean")
```

Plot state-specific mean temperatures

```{r}
ggplot()+
  geom_spatvector(data=conus_t,
                  aes(fill=MEAN))+
  scale_fill_continuous(type="viridis",
                        na.value=NA,
                        "Temperature (°C)")+
  ggtitle("Average Annual Temperature by State in 2021")+
  theme_pubr(legend="bottom")+
  theme(plot.title = element_text(hjust = 0.5),
        axis.line = element_blank(),
        axis.ticks = element_blank(),
        axis.text = element_blank())
```

#### 3.10 Reclassify temperature values based on specific range

Define reclassification matrix.

```{r}
from = c(-Inf,
         25,
         75)
to = c(25,
       75,
       Inf)
becomes = 1:3
reclass = matrix(c(from,
                    to,
                    becomes),
                 ncol = 3)
```

Reclassify according to matrix.

```{r}
narr_reclass = classify(narr_crop_c$range,
                        rcl = reclass,
                        include.lowest = TRUE)
```

Define discrete levels and labels after reclassification.

```{r}
level_values = data.frame(c(1:3),
                          c("1", "2", "3"))
colnames(level_values) = c("range_continuous", "range_discrete")
set.cats(narr_reclass,
         layer = "range",
         value = level_values)
```

Plot reclassified data.

```{r}
ggplot()+
  geom_spatraster(data = narr_reclass$range_discrete)+
  scale_fill_viridis_d("Temperature Range Classification",
                       option = "plasma",
                       labels = c("t < 25°",
                                  "25° ≤ t < 75°",
                                  "75° ≤ t ",
                                  ""),
                       na.value = NA)+
  ggtitle("Reclassified Air Temperature Ranges (2021)")+
  geom_spatvector(data = conus_t,
                  fill = "transparent",
                  color = "black")+
  theme_pubr(legend = "bottom")+
  theme(plot.title = element_text(hjust = 0.5),
        axis.line = element_blank(),
        axis.ticks = element_blank(),
        axis.text = element_blank())
```
